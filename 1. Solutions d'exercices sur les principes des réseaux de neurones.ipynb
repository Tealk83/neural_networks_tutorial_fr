{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Principles\n",
    "\n",
    "Bonjour et bienvenue dans ce notebook consacré aux principes fondamentaux des réseaux de neurones.<br>\n",
    "Nous allons présenter ici, étape par étape, comment un réseau de neurone fonctionne.<br><br>\n",
    "Si vous êtes bloqué, n'hésitez pas à regarder la <a href=\"https://youtu.be/s5X64fmAqUo\">vidéo</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lexml.lexmlexercices import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parfait!\n"
     ]
    }
   ],
   "source": [
    "def activate(entry):\n",
    "    #A faire: : Ecrire une fonction, laquelle retourne 1 si le threshold de 1 est passé, sinon 0.\n",
    "    if(entry >= 1):\n",
    "        return 1\n",
    "    return 0\n",
    "test_activation(activate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 & 0 -> 0 Ok\n",
      "0 & 1 -> 1 Ok\n",
      "1 & 0 -> 1 Ok\n",
      "1 & 1 -> 1 Ok\n",
      "Parfait!\n"
     ]
    }
   ],
   "source": [
    "def or_gate(entry_1, entry_2):\n",
    "    #A faire: Déterminer le poids des neurons pour que la porte\n",
    "    #       s'active si l'un ou l'autre des neurones envoie un signal de 1.\n",
    "    #Note: N'oubliez pas d'utiliser la fonction d'activation.\n",
    "    weight_neuron_1 = 1\n",
    "    weight_neuron_2 = 1\n",
    "    \n",
    "    su = entry_1 * weight_neuron_1 + entry_2 * weight_neuron_2\n",
    "\n",
    "    return activate(su)\n",
    "test_or_gate(or_gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 & 0 -> 0 Ok\n",
      "0 & 1 -> 0 Ok\n",
      "1 & 0 -> 0 Ok\n",
      "1 & 1 -> 1 Ok\n",
      "Parfait!\n"
     ]
    }
   ],
   "source": [
    "def and_gate(entry_1, entry_2):\n",
    "    #A faire: Déterminer le poids des neurons pour que la porte\n",
    "    #      s'active si les 2 neurones envoient un signal de 1.\n",
    "    \n",
    "    weight_neuron_1 = 0.5\n",
    "    weight_neuron_2 = 0.5\n",
    "    \n",
    "    su = entry_1 * weight_neuron_1 + entry_2 * weight_neuron_2\n",
    "    \n",
    "    return activate(su)\n",
    "test_and_gate(and_gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 & 0 -> 0 Ok\n",
      "0 & 1 -> 1 Ok\n",
      "1 & 0 -> 1 Ok\n",
      "1 & 1 -> 0 Ok\n",
      "Parfait!\n"
     ]
    }
   ],
   "source": [
    "def xor_gate_pure_neuron(entry_1, entry_2):\n",
    "    #A faire: En vous basant sur votre travail précédent, créez une porte qui s'active\n",
    "    #Quand entry_1 ou entry_2 envoie la valeur de 1, mais ne s'active pas si les 2 sont activés.\n",
    "    \n",
    "    #Astuce : Utilisez les output de and_gate et or_gate comme input d'une troisième couche.\n",
    "    \n",
    "    w_and = -1\n",
    "    w_or = 1\n",
    "\n",
    "    return w_and * and_gate(entry_1, entry_2) + w_or * or_gate(entry_1, entry_2)\n",
    "test_xor_gate(xor_gate_pure_neuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L'opération logique NOT\n",
    "\n",
    "Inverser un résultat de 0 à 1 ou de 1 à 0 est une opération très courante.<br>\n",
    "La porte logique la réalisant s'appelle la porte NOT.<br>\n",
    "Créez la dans la cellule qui suit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parfait!\n"
     ]
    }
   ],
   "source": [
    "def not_gate(entry):\n",
    "    #A faire: Considérant le code écrit pour votre fonction Activate(), créez une porte qui:\n",
    "    #Donne 0 si le threshold de 1 est passé.\n",
    "    #Donne 1 dans les autres cas.\n",
    "    if(entry >= 1):\n",
    "        return 0\n",
    "    return 1\n",
    "test_not_gate(not_gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 & 0 -> 1 Ok\n",
      "0 & 1 -> 1 Ok\n",
      "1 & 0 -> 1 Ok\n",
      "1 & 1 -> 0 Ok\n",
      "Parfait!\n"
     ]
    }
   ],
   "source": [
    "def nand_gate(entry_1, entry_2):\n",
    "    #A faire: Créer une porte qui retourne 1 tout le temps,\n",
    "    #sauf quand les deux neurones d'entrée envoient un signal en même temps.\n",
    "    \n",
    "    #Astuce : Utilisez les fonctions présentées ci-avant\n",
    "    \n",
    "    return not_gate(and_gate(entry_1, entry_2))\n",
    "test_nand_gate(nand_gate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approche dynamique ou seulement de poids.\n",
    "\n",
    "Dans l'exemple précédent, vous avez vu qu'il était possible de modifier l'activation du neurone pour modifier la porte. Si vous souhaitez qu'un réseau de neurone fonctionne comme cela pour s'entraîner, à savoir modifier la structure de son architecture, nous dirons que vous utilisez une approche __dynamique__.<br>\n",
    "<br>\n",
    "Ce type de stratégie est utilisée dans quelques architectures, telle que les Algorithmes Génétiques.<br>\n",
    "<br>\n",
    "Cependant, le développement de récents algorithmes cherche à éviter ce mode de fonctionnement, principalement pour une efficiacité de calcul. A la place, ceux-ci cherchent à garder une architecture figée, où seuls les poids des neurones changent.<br>\n",
    "<br>\n",
    "Dans l'exemple suivant, cherchez à n'utiliser que le poids des neurones pour créer la porte, __n'utilisez cependant que l'activation activate()__.<br>\n",
    "<br>\n",
    "Si nécessaire, regardez la vidéo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 & 0 -> 1 Ok\n",
      "0 & 1 -> 1 Ok\n",
      "1 & 0 -> 1 Ok\n",
      "1 & 1 -> 0 Ok\n",
      "Parfait!\n"
     ]
    }
   ],
   "source": [
    "def nand_gate_pure_neuron(entry_1, entry_2):\n",
    "    #A faire: Recréez la porte nand, mais sans utiliser la fonction not_gate() pour l'activer.\n",
    "    \n",
    "    w_and = -1\n",
    "    w_bias = 1\n",
    "    \n",
    "    return w_and*(and_gate(entry_1, entry_2))+1*w_bias\n",
    "test_nand_gate(nand_gate_pure_neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 & 0 -> 1 Ok\n",
      "0 & 1 -> 0 Ok\n",
      "1 & 0 -> 0 Ok\n",
      "1 & 1 -> 0 Ok\n",
      "Parfait!\n"
     ]
    }
   ],
   "source": [
    "def nor_gate_pure_neuron(entry_1, entry_2):\n",
    "    #A faire: Sans utiliser la fonction not_gate, créez une porte qui retourne tout le temps 1, \n",
    "    #Sauf quand un neurone est activé.\n",
    "    w_or = -1\n",
    "    return w_or*(or_gate(entry_1, entry_2))+1\n",
    "test_nor_gate(nor_gate_pure_neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 & 0 -> 1 Ok\n",
      "0 & 1 -> 0 Ok\n",
      "1 & 0 -> 0 Ok\n",
      "1 & 1 -> 1 Ok\n",
      "Parfait!\n"
     ]
    }
   ],
   "source": [
    "def xnor_gate_pure_neuron(entry_1, entry_2):\n",
    "    #A faire: Sans utiliser la fonction not_gate, créez une porte qui retourne tout le temps 1, \n",
    "    #Sauf quand un unique neurone est activé.\n",
    "    w_or = -1\n",
    "    return w_or*(xor_gate_pure_neuron(entry_1, entry_2))+1\n",
    "test_xnor_gate(xnor_gate_pure_neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
